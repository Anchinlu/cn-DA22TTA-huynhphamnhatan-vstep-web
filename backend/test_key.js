// File: backend/test_key.js
import 'dotenv/config';

const key = process.env.GROQ_API_KEY || process.env.GEMINI_API_KEY;

if (!key) {
    console.error("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y Key (GROQ_API_KEY) trong file .env!");
    process.exit(1);
}

const url = "https://api.groq.com/openai/v1/models";

console.log(`üîç ƒêang h·ªèi Groq danh s√°ch model kh·∫£ d·ª•ng...`);
console.log(`üîë Key: ${key.substring(0, 10)}...`);
console.log("------------------------------------------------");

async function checkModels() {
    try {
        const response = await fetch(url, {
            method: "GET",
            headers: {
                "Authorization": `Bearer ${key}`,
                "Content-Type": "application/json"
            }
        });

        if (!response.ok) {
            const err = await response.json();
            console.error("‚ùå L·ªñI API:", JSON.stringify(err, null, 2));
            return;
        }

        const data = await response.json();
        const models = data.data;

        console.log("‚úÖ K·∫æT N·ªêI TH√ÄNH C√îNG! D∆∞·ªõi ƒë√¢y l√† c√°c Model b·∫°n ƒë∆∞·ª£c d√πng:");
        console.log("------------------------------------------------");
        
        // L·ªçc ra c√°c model Llama v√† in ra
        models.forEach(m => {
            console.log(`- ${m.id}`);
        });
        
        console.log("------------------------------------------------");
        console.log("üí° G·ª¢I √ù: H√£y ch·ªçn 'llama-3.3-70b-versatile' ho·∫∑c 'llama-3.1-8b-instant' ƒë·ªÉ thay v√†o app.js");

    } catch (err) {
        console.error("‚ùå L·ªói m·∫°ng ho·∫∑c code:", err.message);
    }
}

checkModels();